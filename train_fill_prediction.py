"""
NÄ°LÃœFER BELEDÄ°YESÄ° - KONTEYNER DOLULUK TAHMÄ°N MODELÄ°
Profesyonel Machine Learning Pipeline
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import json
from datetime import datetime

class FillLevelPredictor:
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_importance = {}
        self.metrics = {}
        
    def prepare_features(self, df):
        """Model iÃ§in Ã¶zellikleri hazÄ±rla"""
        print("\nğŸ“Š Ã–zellikler hazÄ±rlanÄ±yor...")
        
        # NaN deÄŸerleri temizle
        df = df.dropna(subset=['expected_fill_level', 'collection_priority'])
        
        # Hedef deÄŸiÅŸken
        y = df['expected_fill_level'].values
        
        # Ã–zellikler
        feature_columns = [
            'days_since_collection',
            'day_of_week', 
            'month',
            'is_weekend',
            'collection_days_per_week',
            'type_encoded',
            'capacity_category',
            'population_density',
            'current_fill_level'
        ]
        
        X = df[feature_columns].copy()
        
        # capacity_category'yi encode et
        category_map = {'small': 1, 'medium': 2, 'large': 3, 'xlarge': 4}
        X['capacity_category'] = X['capacity_category'].map(category_map)
        
        # Eksik deÄŸerleri doldur (sadece numerik kolonlar iÃ§in)
        X = X.fillna(X.median())
        
        print(f"âœ“ {len(feature_columns)} Ã¶zellik kullanÄ±lÄ±yor")
        print(f"âœ“ {len(X)} Ã¶rnek hazÄ±rlandÄ±")
        
        return X, y, feature_columns
    
    def train_model(self, X, y, feature_columns):
        """Modeli eÄŸit ve optimize et"""
        print("\nğŸ“ Model eÄŸitimi baÅŸlÄ±yor...")
        
        # Veriyi bÃ¶l
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Veriyi Ã¶lÃ§eklendir
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        print(f"âœ“ EÄŸitim seti: {len(X_train)} Ã¶rnek")
        print(f"âœ“ Test seti: {len(X_test)} Ã¶rnek")
        
        # RandomForest ile baÅŸla
        print("\nğŸŒ² RandomForest modeli eÄŸitiliyor...")
        rf_model = RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=10,
            min_samples_leaf=4,
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train, y_train)
        
        # GradientBoosting ile karÅŸÄ±laÅŸtÄ±r
        print("ğŸš€ GradientBoosting modeli eÄŸitiliyor...")
        gb_model = GradientBoostingRegressor(
            n_estimators=150,
            learning_rate=0.1,
            max_depth=5,
            random_state=42
        )
        gb_model.fit(X_train, y_train)
        
        # En iyi modeli seÃ§
        rf_score = rf_model.score(X_test, y_test)
        gb_score = gb_model.score(X_test, y_test)
        
        print(f"\nğŸ“ˆ Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
        print(f"   RandomForest RÂ² Skoru: {rf_score:.4f}")
        print(f"   GradientBoosting RÂ² Skoru: {gb_score:.4f}")
        
        if rf_score > gb_score:
            self.model = rf_model
            best_model_name = "RandomForest"
            print(f"\nâœ… RandomForest seÃ§ildi (daha yÃ¼ksek RÂ² skoru)")
        else:
            self.model = gb_model
            best_model_name = "GradientBoosting"
            print(f"\nâœ… GradientBoosting seÃ§ildi (daha yÃ¼ksek RÂ² skoru)")
        
        # Test seti Ã¼zerinde deÄŸerlendirme
        y_pred = self.model.predict(X_test)
        
        # Tahminleri 0-0.95 arasÄ±na sÄ±nÄ±rla
        y_pred = np.clip(y_pred, 0, 0.95)
        
        # Metrikleri hesapla
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        
        self.metrics = {
            'model_name': best_model_name,
            'mae': float(mae),
            'rmse': float(rmse),
            'r2_score': float(r2),
            'train_size': len(X_train),
            'test_size': len(X_test),
            'timestamp': datetime.now().isoformat()
        }
        
        # Ã–zellik Ã¶nemliliÄŸi
        if hasattr(self.model, 'feature_importances_'):
            importances = self.model.feature_importances_
            self.feature_importance = dict(zip(feature_columns, importances))
        
        return X_test, y_test, y_pred
    
    def evaluate_model(self, X_test, y_test, y_pred):
        """Model performansÄ±nÄ± detaylÄ± deÄŸerlendir"""
        print("\n" + "="*80)
        print("ğŸ“Š MODEL PERFORMANS RAPORU")
        print("="*80)
        
        print(f"\nğŸ¯ Model: {self.metrics['model_name']}")
        print(f"ğŸ“… EÄŸitim Tarihi: {self.metrics['timestamp']}")
        print(f"\nğŸ“ Performans Metrikleri:")
        print(f"   â€¢ RÂ² Score (AÃ§Ä±klama GÃ¼cÃ¼): {self.metrics['r2_score']:.4f}")
        print(f"   â€¢ MAE (Ortalama Hata): {self.metrics['mae']:.4f} ({self.metrics['mae']*100:.2f}%)")
        print(f"   â€¢ RMSE (KÃ¶k Ortalama Kare Hata): {self.metrics['rmse']:.4f}")
        
        print(f"\nğŸ“Š Veri Seti BoyutlarÄ±:")
        print(f"   â€¢ EÄŸitim: {self.metrics['train_size']} konteyner")
        print(f"   â€¢ Test: {self.metrics['test_size']} konteyner")
        
        print(f"\nğŸ” Ã–zellik Ã–nemliliÄŸi (Top 5):")
        sorted_features = sorted(self.feature_importance.items(), 
                                key=lambda x: x[1], reverse=True)
        for feature, importance in sorted_features[:5]:
            print(f"   â€¢ {feature:30s}: {importance:.4f}")
        
        # Hata analizi
        errors = np.abs(y_test - y_pred)
        print(f"\nğŸ“‰ Hata Analizi:")
        print(f"   â€¢ %5'in altÄ±nda hata: {(errors < 0.05).sum()} konteyner ({(errors < 0.05).mean()*100:.1f}%)")
        print(f"   â€¢ %10'un altÄ±nda hata: {(errors < 0.10).sum()} konteyner ({(errors < 0.10).mean()*100:.1f}%)")
        print(f"   â€¢ %15'in altÄ±nda hata: {(errors < 0.15).sum()} konteyner ({(errors < 0.15).mean()*100:.1f}%)")
        
        print("\n" + "="*80)
    
    def save_model(self):
        """Modeli ve metadata'yÄ± kaydet"""
        print("\nğŸ’¾ Model kaydediliyor...")
        
        # Model dosyasÄ±
        model_path = 'models/fill_prediction_model.pkl'
        joblib.dump(self.model, model_path)
        print(f"âœ“ Model kaydedildi: {model_path}")
        
        # Scaler dosyasÄ±
        scaler_path = 'models/fill_scaler.pkl'
        joblib.dump(self.scaler, scaler_path)
        print(f"âœ“ Scaler kaydedildi: {scaler_path}")
        
        # Metadata dosyasÄ±
        metadata = {
            'metrics': self.metrics,
            'feature_importance': self.feature_importance
        }
        metadata_path = 'models/fill_model_metadata.json'
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"âœ“ Metadata kaydedildi: {metadata_path}")
        
        print("\nâœ… TÃ¼m dosyalar baÅŸarÄ±yla kaydedildi!")

def main():
    print("="*80)
    print("ğŸš€ NÄ°LÃœFER BELEDÄ°YESÄ° - DOLULUK TAHMÄ°N MODELÄ° EÄÄ°TÄ°MÄ°")
    print("="*80)
    
    # Veriyi yÃ¼kle
    print("\nğŸ“‚ Ä°ÅŸlenmiÅŸ veri yÃ¼kleniyor...")
    df = pd.read_csv('data/processed_containers.csv')
    print(f"âœ“ {len(df)} konteyner verisi yÃ¼klendi")
    
    # Predictor oluÅŸtur
    predictor = FillLevelPredictor()
    
    # Ã–zellikleri hazÄ±rla
    X, y, feature_columns = predictor.prepare_features(df)
    
    # Modeli eÄŸit
    X_test, y_test, y_pred = predictor.train_model(X, y, feature_columns)
    
    # DeÄŸerlendir
    predictor.evaluate_model(X_test, y_test, y_pred)
    
    # Kaydet
    predictor.save_model()
    
    print("\nğŸ‰ Model eÄŸitimi tamamlandÄ±!")
    print("ğŸ“Œ Modeli kullanmak iÃ§in: joblib.load('models/fill_prediction_model.pkl')")

if __name__ == "__main__":
    main()
