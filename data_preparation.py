"""
NilÃ¼fer Belediyesi - Profesyonel Veri HazÄ±rlama ve Analiz ModÃ¼lÃ¼
GerÃ§ek verilerden AI modelleri iÃ§in kaliteli dataset oluÅŸturur
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sqlite3
import json

class DataProcessor:
    def __init__(self):
        self.db_conn = sqlite3.connect('nilufer_waste.db')
        
    def load_raw_data(self):
        """GerÃ§ek CSV verilerini yÃ¼kle ve temizle"""
        print("ðŸ“Š Veri yÃ¼kleniyor...")
        
        # 1. Konteyner sayÄ±larÄ± (mahalle bazlÄ±)
        container_counts = pd.read_csv('data/container_counts.csv', sep=';', encoding='utf-8')
        container_counts.columns = ['SIRA_NO', 'MAHALLE', 'YERALTI', 'LT770', 'LT400', 'PLASTIK', 'TOPLAM']
        print(f"âœ“ Konteyner sayÄ±larÄ±: {len(container_counts)} mahalle")
        
        # 2. Tonaj verileri (aylÄ±k)
        tonnages = pd.read_csv('data/tonnages.csv', encoding='utf-8')
        print(f"âœ“ Tonaj verileri: {len(tonnages)} ay")
        
        # 3. Mahalle toplama rotasyonlarÄ±
        rotations_raw = pd.read_csv('data/neighbor_days_rotations.csv', sep=';', encoding='utf-8')
        rotations_raw.columns = ['MAHALLE', 'TRUCK_TYPE', 'DAYS_PER_WEEK', 'FREQUENCY', 'CRANE_USED', 'CRANE_DAYS']
        rotations_raw['MAHALLE'] = rotations_raw['MAHALLE'].str.strip()
        print(f"âœ“ Rotasyon verileri: {len(rotations_raw)} mahalle")
        
        # 4. AraÃ§ GPS verileri (634,297 kayÄ±t!)
        vehicle_logs = pd.read_csv('data/all_merged_data.csv', encoding='utf-8', on_bad_lines='skip')
        print(f"âœ“ GPS verileri: {len(vehicle_logs):,} kayÄ±t")
        
        # 5. Mahalle nÃ¼fus verileri
        population = pd.read_csv('data/mahalle_nufus.csv', encoding='utf-8')
        print(f"âœ“ NÃ¼fus verileri: {len(population)} mahalle")
        
        return {
            'container_counts': container_counts,
            'tonnages': tonnages,
            'rotations': rotations_raw,
            'vehicle_logs': vehicle_logs,
            'population': population
        }
    
    def extract_container_locations(self, vehicle_logs):
        """GPS verilerinden konteyner konumlarÄ±nÄ± Ã§Ä±kar"""
        print("\nðŸ—ºï¸ Konteyner konumlarÄ± Ã§Ä±karÄ±lÄ±yor...")
        
        # Duraklama sÃ¼resini dakikaya Ã§evir (HH:MM:SS formatÄ±ndan)
        def parse_duration(duration_str):
            try:
                if pd.isna(duration_str) or duration_str == '00:00:00':
                    return 0
                parts = str(duration_str).split(':')
                hours = int(parts[0])
                minutes = int(parts[1])
                seconds = int(parts[2])
                return hours * 60 + minutes + seconds / 60
            except:
                return 0
        
        vehicle_logs['duration_minutes'] = vehicle_logs['Duraklama SÃ¼resi'].apply(parse_duration)
        
        # Duraklamalar (konteyner toplama noktalarÄ± olabilir) - 5 dakikadan uzun duraklamalar
        stops = vehicle_logs[vehicle_logs['duration_minutes'] > 5].copy()
        
        # Mahalle bazlÄ± gruplama
        location_clusters = stops.groupby('Mahalle').agg({
            'Enlem': 'mean',
            'Boylam': 'mean',
            'duration_minutes': 'mean',
            '#': 'count'
        }).reset_index()
        
        location_clusters.columns = ['Mahalle', 'Lat', 'Lng', 'Avg_Stop_Duration', 'Stop_Count']
        
        print(f"âœ“ {len(location_clusters)} mahallede konum bilgisi bulundu")
        return location_clusters
    
    def create_container_features(self, raw_data):
        """Konteynerler iÃ§in zengin Ã¶zellikler oluÅŸtur"""
        print("\nðŸ”§ Feature Engineering baÅŸlÄ±yor...")
        
        # Database'den mevcut konteynerleri al
        containers = pd.read_sql_query("""
            SELECT c.container_id as id, c.neighborhood_id, c.container_type, c.capacity_liters,
                   c.latitude, c.longitude, c.current_fill_level, c.last_collection_date,
                   n.neighborhood_name, n.population
            FROM containers c
            JOIN neighborhoods n ON c.neighborhood_id = n.neighborhood_id
        """, self.db_conn)
        
        print(f"âœ“ Database'den {len(containers)} konteyner alÄ±ndÄ±")
        
        # 1. Zaman Ã¶zellikleri
        containers['last_collection_date'] = pd.to_datetime(containers['last_collection_date'], format='%Y-%m-%d', errors='coerce')
        containers['days_since_collection'] = (datetime.now() - containers['last_collection_date']).dt.days
        containers['day_of_week'] = containers['last_collection_date'].dt.dayofweek
        containers['month'] = containers['last_collection_date'].dt.month
        containers['is_weekend'] = containers['day_of_week'].isin([5, 6]).astype(int)
        
        # 2. Mahalle Ã¶zellikleri ekle
        # Rotasyon bilgileri
        rotations = raw_data['rotations']
        rot_dict = {}
        for _, row in rotations.iterrows():
            mahalle = row['MAHALLE'].upper().strip()
            try:
                days = int(row['DAYS_PER_WEEK']) if pd.notna(row['DAYS_PER_WEEK']) else 3
            except:
                days = 3
            rot_dict[mahalle] = days
        
        containers['collection_days_per_week'] = containers['neighborhood_name'].str.upper().map(rot_dict).fillna(3)
        
        # Tonaj ortalamalarÄ± (son aylar)
        tonnages = raw_data['tonnages']
        avg_daily_tonnage = tonnages['Ortalama GÃ¼nlÃ¼k Tonaj (TON)'].mean()
        
        # 3. Konteyner tipi Ã¶zellikleri
        type_encoding = {
            'plastic': 1,
            '400lt': 2,
            '770lt': 3,
            'underground': 4,
            '5000lt': 5
        }
        containers['type_encoded'] = containers['container_type'].map(type_encoding).fillna(1)
        
        # 4. Kapasite Ã¶zellikleri
        containers['capacity_category'] = pd.cut(containers['capacity_liters'], 
                                                   bins=[0, 300, 500, 1000, 6000],
                                                   labels=['small', 'medium', 'large', 'xlarge'])
        
        # 5. NÃ¼fus yoÄŸunluÄŸu (proxy)
        containers['population_density'] = containers['population'] / 1000  # normalize
        
        # 6. Beklenen doluluk oranÄ± (gÃ¼nlÃ¼k artÄ±ÅŸ modeli)
        daily_fill_rate = 0.08  # Ortalama %8 gÃ¼nlÃ¼k doluluk artÄ±ÅŸÄ±
        containers['expected_fill_level'] = np.minimum(
            0.95,
            containers['current_fill_level'] + (containers['days_since_collection'] * daily_fill_rate)
        )
        
        # 7. Toplama Ã¶nceliÄŸi
        containers['collection_priority'] = (
            containers['expected_fill_level'] * 0.5 +  # Doluluk
            (containers['days_since_collection'] / 10) * 0.3 +  # GÃ¼n sayÄ±sÄ±
            (containers['population_density'] / containers['population_density'].max()) * 0.2  # NÃ¼fus
        )
        
        print(f"âœ“ {len(containers.columns)} Ã¶zellik oluÅŸturuldu")
        print(f"  - Zaman: days_since_collection, day_of_week, month, is_weekend")
        print(f"  - Mahalle: collection_days_per_week, population_density")
        print(f"  - Konteyner: type_encoded, capacity_category")
        print(f"  - Hedef: expected_fill_level, collection_priority")
        
        return containers
    
    def save_processed_data(self, containers, output_file='data/processed_containers.csv'):
        """Ä°ÅŸlenmiÅŸ veriyi kaydet"""
        containers.to_csv(output_file, index=False, encoding='utf-8')
        print(f"\nðŸ’¾ Veri kaydedildi: {output_file}")
        return output_file

def main():
    print("="*80)
    print("ðŸš€ NÄ°LÃœFER BELEDÄ°YESÄ° - PROFESYONEL VERÄ° HAZIRLAMA")
    print("="*80)
    
    processor = DataProcessor()
    
    # AdÄ±m 1: Ham veriyi yÃ¼kle
    raw_data = processor.load_raw_data()
    
    # AdÄ±m 2: Konteyner konumlarÄ±
    locations = processor.extract_container_locations(raw_data['vehicle_logs'])
    
    # AdÄ±m 3: Feature engineering
    processed_containers = processor.create_container_features(raw_data)
    
    # AdÄ±m 4: Kaydet
    output_file = processor.save_processed_data(processed_containers)
    
    # Ã–zet istatistikler
    print("\nðŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER:")
    print(f"Toplam Konteyner: {len(processed_containers)}")
    print(f"Ortalama Doluluk: {processed_containers['current_fill_level'].mean():.2%}")
    print(f"YÃ¼ksek Ã–ncelikli (>0.7): {len(processed_containers[processed_containers['collection_priority'] > 0.7])}")
    print(f"Son 3 GÃ¼n Ä°Ã§inde ToplanmÄ±ÅŸ: {len(processed_containers[processed_containers['days_since_collection'] <= 3])}")
    
    print("\nâœ… Veri hazÄ±rlama tamamlandÄ±!")
    print(f"ðŸ“ Ã‡Ä±ktÄ± dosyasÄ±: {output_file}")
    
    processor.db_conn.close()

if __name__ == '__main__':
    main()
