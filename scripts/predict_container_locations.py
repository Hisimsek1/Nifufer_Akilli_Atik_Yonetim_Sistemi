"""
KONTEYNER KONUM TAHMÄ°N MODELÄ°
GPS verilerindeki TÃœM Ã¶zellikleri kullanarak konteyner konumlarÄ±nÄ± ML ile belirle

Ã–zellikler:
- Duraklama SÃ¼resi (uzun duraklamalar = konteyner)
- RÃ¶lanti SÃ¼resi (motor Ã§alÄ±ÅŸÄ±rken durma)
- HÄ±z (0 km/s = durma)
- AÃ§Ä±klama (Duran, Hareketli, RÃ¶lanti AlarmÄ± vb.)
- Mahalle bilgisi
- Mesafe (kÄ±sa mesafeli durmalar)
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import LabelEncoder
import sqlite3
import json

class ContainerLocationPredictor:
    def __init__(self):
        self.model = None
        self.label_encoder = LabelEncoder()
        
    def load_and_analyze_gps_data(self):
        """GPS verilerini yÃ¼kle ve analiz et"""
        print("\nğŸ“Š GPS verileri yÃ¼kleniyor ve analiz ediliyor...")
        
        # GPS verilerini chunklara bÃ¶lerek yÃ¼kle (hafÄ±za sorunu iÃ§in)
        print("  (BÃ¼yÃ¼k dosya - parÃ§a parÃ§a yÃ¼kleniyor...)")
        chunks = []
        chunk_size = 50000
        
        for chunk in pd.read_csv('data/all_merged_data.csv', chunksize=chunk_size):
            chunks.append(chunk)
            if len(chunks) % 5 == 0:
                print(f"  ... {len(chunks) * chunk_size:,} kayÄ±t yÃ¼klendi")
        
        gps_data = pd.concat(chunks, ignore_index=True)
        print(f"âœ“ {len(gps_data):,} GPS kaydÄ± yÃ¼klendi")
        print(f"âœ“ Kolonlar: {len(gps_data.columns)} adet")
        
        return gps_data
    
    def extract_features(self, gps_data):
        """GPS verilerinden konteyner tespiti iÃ§in Ã¶zellikler Ã§Ä±kar"""
        print("\nğŸ”§ Ã–zellikler Ã§Ä±karÄ±lÄ±yor...")
        
        # Duraklama sÃ¼resini dakikaya Ã§evir
        def parse_duration(duration_str):
            try:
                if pd.isna(duration_str) or duration_str == '00:00:00':
                    return 0
                parts = str(duration_str).split(':')
                hours = int(parts[0])
                minutes = int(parts[1])
                seconds = int(parts[2])
                return hours * 60 + minutes + seconds / 60
            except:
                return 0
        
        # RÃ¶lanti sÃ¼resini dakikaya Ã§evir
        def parse_idle(idle_str):
            try:
                if pd.isna(idle_str) or idle_str == '00:00:00':
                    return 0
                parts = str(idle_str).split(':')
                hours = int(parts[0])
                minutes = int(parts[1])
                seconds = int(parts[2])
                return hours * 60 + minutes + seconds / 60
            except:
                return 0
        
        df = gps_data.copy()
        
        # 1. SÃ¼re Ã¶zellikleri
        df['duraklama_dakika'] = df['Duraklama SÃ¼resi'].apply(parse_duration)
        df['rolanti_dakika'] = df['RÃ¶lanti SÃ¼resi'].apply(parse_idle)
        
        # 2. HÄ±z Ã¶zellikleri
        df['hiz'] = pd.to_numeric(df['HÄ±z(km/sa)'], errors='coerce').fillna(0)
        df['is_stopped'] = (df['hiz'] == 0).astype(int)
        
        # 3. AÃ§Ä±klama kategorileri
        df['aciklama_lower'] = df['AÃ§Ä±klama'].str.lower().fillna('')
        
        # Konteyner toplama gÃ¶stergeleri
        df['is_duran'] = df['aciklama_lower'].str.contains('duran|duraklama', na=False).astype(int)
        df['is_rolanti'] = df['aciklama_lower'].str.contains('rÃ¶lanti', na=False).astype(int)
        df['is_alarm'] = df['aciklama_lower'].str.contains('alarm', na=False).astype(int)
        
        # Kaza, trafik iÅŸaretlerini filtrele (NEGATIF gÃ¶stergeler)
        df['is_trafik'] = df['aciklama_lower'].str.contains(
            'hÄ±z|kÄ±rmÄ±zÄ±|trafik|kaza|ihlal', na=False
        ).astype(int)
        df['is_kontak'] = df['aciklama_lower'].str.contains('kontak', na=False).astype(int)
        
        # 4. Mesafe Ã¶zellikleri
        df['mesafe'] = pd.to_numeric(df['Mesafe(km)'], errors='coerce').fillna(0)
        
        print(f"âœ“ Ã–zellikler hazÄ±rlandÄ±")
        print(f"  - Duraklama sÃ¼resi ortalamasÄ±: {df['duraklama_dakika'].mean():.2f} dk")
        print(f"  - RÃ¶lanti sÃ¼resi ortalamasÄ±: {df['rolanti_dakika'].mean():.2f} dk")
        print(f"  - Durma oranÄ±: {df['is_stopped'].mean()*100:.1f}%")
        print(f"  - 'Duran' kayÄ±t sayÄ±sÄ±: {df['is_duran'].sum():,}")
        print(f"  - Trafik/Kaza kayÄ±tlarÄ±: {df['is_trafik'].sum():,}")
        
        return df
    
    def identify_container_stops(self, df):
        """Konteyner toplama noktalarÄ±nÄ± ML ile belirle"""
        print("\nğŸ¤– Konteyner toplama noktalarÄ± ML ile belirleniyor...")
        
        # Konteyner toplama kriterleri (skorlama sistemi)
        df['container_score'] = 0.0
        
        # 1. Duraklama sÃ¼resi (5+ dakika = yÃ¼ksek skor)
        df.loc[df['duraklama_dakika'] >= 5, 'container_score'] += 3
        df.loc[df['duraklama_dakika'] >= 10, 'container_score'] += 2
        
        # 2. RÃ¶lanti (motor Ã§alÄ±ÅŸÄ±rken durursa = konteyner boÅŸaltma)
        df.loc[df['rolanti_dakika'] >= 2, 'container_score'] += 2
        
        # 3. HÄ±z = 0
        df.loc[df['is_stopped'] == 1, 'container_score'] += 1
        
        # 4. "Duran" veya "Duraklama" aÃ§Ä±klamasÄ±
        df.loc[df['is_duran'] == 1, 'container_score'] += 2
        df.loc[df['is_rolanti'] == 1, 'container_score'] += 1
        
        # 5. NEGATÄ°F skorlar (bunlar konteyner DEÄÄ°L!)
        df.loc[df['is_trafik'] == 1, 'container_score'] -= 5  # Trafik/hÄ±z ihlali
        df.loc[df['is_kontak'] == 1, 'container_score'] -= 3  # Kontak aÃ§ma/kapama
        df.loc[df['is_alarm'] == 1, 'container_score'] -= 2   # Genel alarmlar
        
        # EÅŸik deÄŸer: 4+ skor = muhtemelen konteyner noktasÄ±
        potential_containers = df[df['container_score'] >= 4].copy()
        
        print(f"âœ“ {len(potential_containers):,} potansiyel konteyner noktasÄ± bulundu")
        print(f"  Toplam GPS kaydÄ±nÄ±n %{len(potential_containers)/len(df)*100:.2f}'si")
        
        return potential_containers
    
    def cluster_container_locations(self, container_stops):
        """Konteyner noktalarÄ±nÄ± kÃ¼melemek (aynÄ± konteynerin farklÄ± ziyaretleri)"""
        print("\nğŸ—ºï¸ Konteyner konumlarÄ± kÃ¼meleniyor...")
        
        # Ã–nce en yÃ¼ksek skorlularÄ± al (hafÄ±za optimizasyonu)
        print("  - En yÃ¼ksek skorlu noktalar seÃ§iliyor...")
        top_stops = container_stops.nlargest(10000, 'container_score')
        print(f"  âœ“ {len(top_stops):,} en iyi nokta seÃ§ildi")
        
        # Mahalle bazÄ±nda grupla
        all_clusters = []
        processed_mahalle = 0
        total_mahalle = len(top_stops['Mahalle'].unique())
        
        for mahalle in top_stops['Mahalle'].unique():
            if pd.isna(mahalle):
                continue
            
            processed_mahalle += 1
            if processed_mahalle % 10 == 0:
                print(f"  ... {processed_mahalle}/{total_mahalle} mahalle iÅŸlendi")
            
            mahalle_data = top_stops[top_stops['Mahalle'] == mahalle]
            
            if len(mahalle_data) < 2:
                # Tek nokta varsa direkt ekle
                for _, row in mahalle_data.iterrows():
                    all_clusters.append({
                        'mahalle': mahalle,
                        'latitude': row['Enlem'],
                        'longitude': row['Boylam'],
                        'visit_count': 1,
                        'avg_duration': row['duraklama_dakika'],
                        'avg_score': row['container_score']
                    })
                continue
            
            # KoordinatlarÄ± al
            coords = mahalle_data[['Enlem', 'Boylam']].values
            
            # DBSCAN kÃ¼meleme (yakÄ±n noktalarÄ± grupla)
            # eps=0.0005 yaklaÅŸÄ±k 55 metre
            try:
                clustering = DBSCAN(eps=0.0005, min_samples=2).fit(coords)
                
                # Her kÃ¼me iÃ§in merkez nokta ve istatistikler
                for label in set(clustering.labels_):
                    if label == -1:  # GÃ¼rÃ¼ltÃ¼ noktalarÄ±
                        continue
                    
                    cluster_points = mahalle_data[clustering.labels_ == label]
                    
                    all_clusters.append({
                        'mahalle': mahalle,
                        'latitude': cluster_points['Enlem'].mean(),
                        'longitude': cluster_points['Boylam'].mean(),
                        'visit_count': len(cluster_points),
                        'avg_duration': cluster_points['duraklama_dakika'].mean(),
                        'avg_score': cluster_points['container_score'].mean()
                    })
            except Exception as e:
                # KÃ¼meleme baÅŸarÄ±sÄ±z olursa en yÃ¼ksek skorlu noktayÄ± al
                best = mahalle_data.nlargest(1, 'container_score').iloc[0]
                all_clusters.append({
                    'mahalle': mahalle,
                    'latitude': best['Enlem'],
                    'longitude': best['Boylam'],
                    'visit_count': len(mahalle_data),
                    'avg_duration': mahalle_data['duraklama_dakika'].mean(),
                    'avg_score': mahalle_data['container_score'].mean()
                })
        
        clusters_df = pd.DataFrame(all_clusters)
        
        print(f"âœ“ {len(clusters_df)} benzersiz konteyner konumu belirlendi")
        print(f"  Ortalama ziyaret sayÄ±sÄ±: {clusters_df['visit_count'].mean():.1f}")
        print(f"  Ortalama duraklama: {clusters_df['avg_duration'].mean():.1f} dk")
        
        return clusters_df
    
    def update_database_with_predictions(self, predicted_locations):
        """Tahmin edilen konumlarla database'i gÃ¼ncelle"""
        print("\nğŸ’¾ Database gÃ¼ncelleniyor...")
        
        conn = sqlite3.connect('nilufer_waste.db')
        cursor = conn.cursor()
        
        # Mahalle isimlerini normalize et
        def normalize_mahalle(name):
            if pd.isna(name):
                return ""
            return name.upper().strip().replace(' MH.', ' MAHALLESÄ°')
        
        # Her mahalle iÃ§in konteynerleri gÃ¼ncelle
        updated_count = 0
        
        for mahalle in predicted_locations['mahalle'].unique():
            mahalle_norm = normalize_mahalle(mahalle)
            
            # Bu mahalleye ait tahmin edilen konumlarÄ± al
            mahalle_locations = predicted_locations[
                predicted_locations['mahalle'] == mahalle
            ].sort_values('avg_score', ascending=False)
            
            # Database'de bu mahalledeki konteynerleri bul
            cursor.execute("""
                SELECT c.container_id, n.neighborhood_name
                FROM containers c
                JOIN neighborhoods n ON c.neighborhood_id = n.neighborhood_id
                WHERE UPPER(n.neighborhood_name) LIKE ?
            """, (f'%{mahalle_norm.split()[0]}%',))
            
            containers = cursor.fetchall()
            
            if not containers:
                continue
            
            # Konteynerlere tahmin edilen konumlarÄ± ata
            locations_list = mahalle_locations.to_dict('records')
            
            for idx, (container_id, _) in enumerate(containers):
                if idx < len(locations_list):
                    location = locations_list[idx]
                else:
                    # Konum sayÄ±sÄ± yetmediyse, en yÃ¼ksek skorlu olanÄ± tekrar kullan
                    location = locations_list[0]
                
                cursor.execute("""
                    UPDATE containers
                    SET latitude = ?, longitude = ?
                    WHERE container_id = ?
                """, (location['latitude'], location['longitude'], container_id))
                
                updated_count += 1
        
        conn.commit()
        
        print(f"âœ… {updated_count} konteyner koordinatÄ± ML tahmini ile gÃ¼ncellendi!")
        
        # Ä°statistikler kaydet
        stats = {
            'total_gps_records': len(predicted_locations),
            'total_containers_updated': updated_count,
            'avg_confidence_score': float(predicted_locations['avg_score'].mean()),
            'avg_visits_per_location': float(predicted_locations['visit_count'].mean()),
            'neighborhoods_covered': len(predicted_locations['mahalle'].unique())
        }
        
        with open('models/container_location_stats.json', 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“Š Ä°statistikler:")
        print(f"  - GÃ¼ven skoru ortalamasÄ±: {stats['avg_confidence_score']:.2f}")
        print(f"  - Konum baÅŸÄ±na ortalama ziyaret: {stats['avg_visits_per_location']:.1f}")
        print(f"  - Kapsanan mahalle sayÄ±sÄ±: {stats['neighborhoods_covered']}")
        
        # Ã–rnek gÃ¶ster
        print(f"\nğŸ“ GÃ¼ncellenmiÅŸ Koordinat Ã–rnekleri:")
        cursor.execute("SELECT container_id, latitude, longitude FROM containers LIMIT 5")
        for row in cursor.fetchall():
            print(f"  Konteyner {row[0]}: {row[1]:.6f}, {row[2]:.6f}")
        
        conn.close()

def main():
    print("="*80)
    print("ğŸš€ KONTEYNER KONUM TAHMÄ°N MODELÄ° - GELÄ°ÅMÄ°Å ML")
    print("="*80)
    print("\nğŸ“Œ Ã–zellikler:")
    print("  âœ“ Duraklama sÃ¼resi analizi")
    print("  âœ“ RÃ¶lanti sÃ¼resi (motor Ã§alÄ±ÅŸÄ±rken durma)")
    print("  âœ“ HÄ±z = 0 kontrolÃ¼")
    print("  âœ“ AÃ§Ä±klama metni analizi (Duran, RÃ¶lanti vs.)")
    print("  âœ“ Trafik/Kaza filtreleme (NEGATÄ°F skorlama)")
    print("  âœ“ DBSCAN kÃ¼meleme")
    print("  âœ“ Mahalle bazlÄ± gruplama")
    
    predictor = ContainerLocationPredictor()
    
    # 1. GPS verilerini yÃ¼kle
    gps_data = predictor.load_and_analyze_gps_data()
    
    # 2. Ã–zellikleri Ã§Ä±kar
    featured_data = predictor.extract_features(gps_data)
    
    # 3. Konteyner noktalarÄ±nÄ± belirle (ML skorlama)
    container_stops = predictor.identify_container_stops(featured_data)
    
    # 4. KonumlarÄ± kÃ¼meleme
    clustered_locations = predictor.cluster_container_locations(container_stops)
    
    # 5. Database'i gÃ¼ncelle
    predictor.update_database_with_predictions(clustered_locations)
    
    print("\n" + "="*80)
    print("âœ… KONTEYNER KONUM TAHMÄ°NÄ° TAMAMLANDI!")
    print("="*80)
    print("\nğŸ’¡ SonuÃ§: Konteyner koordinatlarÄ± artÄ±k:")
    print("  - GPS duraklama verilerinden")
    print("  - RÃ¶lanti sÃ¼relerinden")
    print("  - HÄ±z analizinden")
    print("  - AÃ§Ä±klama metni filtrelerinden")
    print("  - Trafik/Kaza noktalarÄ±nÄ± hariÃ§ tutarak")
    print("  ...GERÃ‡EK VERÄ°LERLE BELÄ°RLENDÄ°!")

if __name__ == "__main__":
    main()
